{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import math\n",
    "from nilearn.image import resample_img\n",
    "from nilearn import plotting\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import statistics\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "os.chdir('/projects/hulacon/shared/neu_data/AVFP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\n",
      "['sub_118']\n",
      "edge: 5 voxels\n",
      "volume: 125 voxels\n"
     ]
    }
   ],
   "source": [
    "subj_num=list(range(16,17))\n",
    "print(subj_num)\n",
    "#get subject name from log file names\n",
    "logfile_folder = 'AffVidsMem_logfiles'\n",
    "data_folder = '36p'\n",
    "subj_dir = [i.split('.txt')[0].split('fmri_')[-1] for i in glob.glob(logfile_folder+'/AffVidsMem*sub*.txt')]\n",
    "subj_dir.sort()\n",
    "print([subj_dir[i] for i in subj_num])\n",
    "\n",
    "search_size = 5 #edge in voxel size\n",
    "vox = int((search_size-1)/2) #number of voxels from center voxel\n",
    "search_size = vox*2+1\n",
    "print('edge: '+str(search_size)+' voxels')\n",
    "print('volume: '+str(search_size**3)+' voxels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_header = ['Video_name', 'video_number', 'video_category(1-H 2-SO 3-SP)', 'novel_vs_familiar(1-N,2-Old)', 'run_number', 'video_onset', 'video_offset', 'video_duration_method1', 'video_duration_method2', 'Fear_rating_onset', 'fear_rating', 'fear_rating_RT', 'Arousal_rating_onset', 'arousal_rating', 'arousal_rating_RT', 'Valence_rating_onset', 'valence_rating', 'valence_rating_RT']\n",
    "num_vid = pd.read_table(glob.glob(os.path.join(logfile_folder,'*'+subj_dir[0]+'.txt'))[0], sep=' ', header=None, names = log_header, index_col=False).shape[0]\n",
    "#sample subj data img for resampling\n",
    "subj_data_img = nib.load(glob.glob(os.path.join(data_folder,'sub-'+subj_dir[0][-3:]+'_run1_36p_mc_MNI_masked.nii.gz'))[0])\n",
    "subj_data = subj_data_img.get_fdata()\n",
    "\n",
    "TR=0.8\n",
    "num_TR = 600\n",
    "TR_series = [x*0.8 for x in range(0, num_TR)]\n",
    "TR_BOLD_offset = 7\n",
    "TR_video_duration = 26 #video_duration/0.8=25.6 round to 26\n",
    "TR_mean_rating= 5.3*3 #rating_duration/0.8=5.3 \n",
    "TR_mean_mean_ITI = 6 #ITI_duration/0.8=5.8 round to 6\n",
    "TR_trial_end = TR_video_duration+TR_mean_rating+TR_mean_mean_ITI\n",
    "\n",
    "#find the index of the closest number to K in a list\n",
    "def closest(lst, K): \n",
    "    val = lst[min(range(len(lst)), key = lambda i: abs(lst[i]-K))] \n",
    "    idx = lst.index(val)\n",
    "    return idx\n",
    "\n",
    "#use index of finding value x in 2D array (b) of value x as index of the first 2 dimensions for 3D array (a)\n",
    "def select3Dfrom2D(a,b,x):\n",
    "    b=old_vid.astype(int)\n",
    "    \n",
    "    new_array = []\n",
    "    for dim1 in list(set(np.where(b==x)[0])):\n",
    "        new_array.append(a[dim1,np.where(b==x)[1][np.where(b==x)[0]==dim1],:])\n",
    "    new_array = np.array(new_array)\n",
    "    \n",
    "    return new_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get grey matter mask\n",
    "save_dir = '/home/chendanl/wrkdir/ISECmem_timecourse_searchlight_correlation_analysis/a'+str(search_size)+'/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "# mask = '/home/chendanl/roi/HarvardOxford/HarvardOxford-cort-maxprob-thr25-1mm.nii.gz'\n",
    "# mask = '/home/chendanl/roi/HarvardOxford/HarvardOxford-sub-maxprob-thr25-1mm.nii.gz'\n",
    "mask = '/home/chendanl/roi/mni_icbm152_gm_tal_nlin_asym_09a_thresh30.nii.gz'\n",
    "mask_img = nib.load(mask)\n",
    "mask_img = resample_img(mask_img,\n",
    "                        target_affine=subj_data_img.affine,\n",
    "                        target_shape=subj_data_img.shape[0:3],\n",
    "                        interpolation='nearest')\n",
    "\n",
    "#get num of voxels\n",
    "# mask_location = np.where((mask_img.get_fdata()!=0) & (subj_data[:,:,:,0]!=0))\n",
    "mask_location = np.where(mask_img.get_fdata()!=0)\n",
    "mask_size = list(range(mask_location[0].shape[0]))\n",
    "\n",
    "# nib.save(mask_img, '/home/chendanl/wrkdir/roi.nii.gz')\n",
    "# display = plotting.plot_roi('/home/chendanl/wrkdir/roi.nii.gz', bg_img='/home/chendanl/roi/mni_icbm152_t1_tal_nlin_sym_09b_hires.nii')\n",
    "# plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16: sub_118\n",
      "\n",
      "Social\n",
      "working on 658 out of 166077 voxels, 0.3962017618333665% done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:78: RuntimeWarning: Mean of empty slice\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:79: RuntimeWarning: Mean of empty slice\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:119: RuntimeWarning: Mean of empty slice\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:127: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:128: RuntimeWarning: Mean of empty slice\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:135: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:136: RuntimeWarning: Mean of empty slice\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:143: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:144: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 689 out of 166077 voxels, 0.4148678022844825% done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:70: RuntimeWarning: Mean of empty slice\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:71: RuntimeWarning: Mean of empty slice\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:116: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 166077 out of 166077 voxels, 100.0% done\n",
      "Spiders\n",
      "working on 166077 out of 166077 voxels, 100.0% done\n",
      "Heights\n",
      "working on 166077 out of 166077 voxels, 100.0% done"
     ]
    }
   ],
   "source": [
    "for s in subj_num:\n",
    "    subj = subj_dir[s]\n",
    "    print('\\n'+str(s)+': '+subj)\n",
    "\n",
    "    #set template for result map\n",
    "    result_template_brain = mask_img.get_fdata().copy()\n",
    "    result_template_brain[:]=np.nan\n",
    "    result_template_brain_new = result_template_brain.copy()\n",
    "    result_template_brain_old = result_template_brain.copy()\n",
    "\n",
    "    #run 1 data\n",
    "    subj_run1_f = glob.glob(os.path.join(data_folder,'sub-'+subj[-3:]+'_run1_36p_mc_MNI_masked.nii.gz'))[0]\n",
    "    subj_run1_img = nib.load(subj_run1_f)\n",
    "    subj_run1_data = subj_run1_img.get_fdata()\n",
    "    subj_run1_data[mask_img==0] = np.nan\n",
    "\n",
    "    #run 2 data\n",
    "    subj_run2_f = glob.glob(os.path.join(data_folder,'sub-'+subj[-3:]+'_run2_36p_mc_MNI_masked.nii.gz'))[0]\n",
    "    subj_run2_img = nib.load(subj_run2_f)\n",
    "    subj_run2_data = subj_run2_img.get_fdata()\n",
    "    subj_run2_data[mask_img==0] = np.nan\n",
    "\n",
    "    # from nilearn import datasets\n",
    "    # from nilearn import surface\n",
    "    # hemispheres = ['right','left']\n",
    "    # pial_mesh = fsaverage['pial_' + hemi]\n",
    "    # subj_run1_img_surface = surface.vol_to_surf(subj_run1_img, pial_mesh).T\n",
    "    # plotting.view_surf(fsaverage.infl_right, subj_run1_img_surface[0,], bg_map=fsaverage.sulc_right)\n",
    "    \n",
    "    #read subject log file\n",
    "    subj_log_f = glob.glob(os.path.join(logfile_folder,'AffVidsMem*'+subj+'.txt'))[0]\n",
    "    subj_log_complete = pd.read_table(subj_log_f, sep=' ', header=None, names = log_header, index_col=False)\n",
    "\n",
    "    #condition selection from subject log\n",
    "    for fearType in ['Social', 'Spiders', 'Heights']:\n",
    "        print('\\n'+fearType)\n",
    "\n",
    "        #condition selection from subject log\n",
    "        subj_log = subj_log_complete[subj_log_complete['Video_name'].str.contains(fearType)]\n",
    "        subj_log = subj_log.reset_index()\n",
    "        num_vid = len(subj_log)\n",
    "    \n",
    "        #loop through all voxels\n",
    "        for mask_coordinate in mask_size:\n",
    "            #     start_time = time.time()\n",
    "            print('\\rworking on '+str(mask_coordinate) + ' out of '+str(max(mask_size)) + ' voxels, ' +str((mask_coordinate)/max(mask_size)*100) + '% done', end=\"\")\n",
    "\n",
    "            #get the coordinates of the centered voxel\n",
    "            x = mask_location[0][mask_coordinate]\n",
    "            y = mask_location[1][mask_coordinate]\n",
    "            z = mask_location[2][mask_coordinate]\n",
    "\n",
    "            #get the range of coordinates based on the edge size vox\n",
    "            x_min = x-vox; y_min = y-vox; z_min = z-vox\n",
    "            x_max = x+vox+1; y_max = y+vox+1; z_max = z+vox+1;\n",
    "    #         if x-vox < 0: x_min = 0\n",
    "    #         if y-vox < 0: y_min = 0\n",
    "    #         if z-vox < 0: z_min = 0\n",
    "    #         if x+vox+1 > subj_data_img.shape[0]: x_max = subj_data_img.shape[0]\n",
    "    #         if y+vox+1 > subj_data_img.shape[1]: y_max = subj_data_img.shape[1]\n",
    "    #         if z+vox+1 > subj_data_img.shape[2]: z_max = subj_data_img.shape[2]\n",
    "            \n",
    "            #calculate ITI period average\n",
    "            #get averanged run 1 rest data\n",
    "            rest_mean_run1_temp = []\n",
    "            for n in list(range(0,int(num_vid/2)-1)):\n",
    "                #add TR offset to find time for ITI period\n",
    "                subj_run1_rest_data = subj_run1_data[x_min:x_max,y_min:y_max,z_min:z_max,closest(TR_series, (subj_log['Valence_rating_onset'][n]+TR_BOLD_offset+(TR_mean_rating/3)*TR)): closest(TR_series, subj_log['video_onset'][n+1]+TR_BOLD_offset)]\n",
    "                subj_run1_rest_data[subj_run1_rest_data==0.]=np.nan\n",
    "                rest_mean_run1_temp.append(np.nanmean(subj_run1_rest_data)) \n",
    "            rest_mean_run1 = np.nanmean(rest_mean_run1_temp)\n",
    "            #get averanged run 2 rest data\n",
    "            rest_mean_run2_temp = []\n",
    "            for n in list(range(int(num_vid/2), num_vid-1)):\n",
    "                #add TR offset to find time for ITI period\n",
    "                subj_run2_rest_data = subj_run2_data[x_min:x_max,y_min:y_max,z_min:z_max,closest(TR_series, (subj_log['Valence_rating_onset'][n]+TR_BOLD_offset+(TR_mean_rating/3)*TR)): closest(TR_series, subj_log['video_onset'][n+1]+TR_BOLD_offset)]\n",
    "                subj_run2_rest_data[subj_run2_rest_data==0.]=np.nan\n",
    "                rest_mean_run2_temp.append(np.nanmean(subj_run2_rest_data)) \n",
    "            rest_mean_run2 = np.nanmean(rest_mean_run2_temp)\n",
    "\n",
    "            #initialize list for averaged acitivty in mask: vid x TR\n",
    "            vid_avg_activity_rest_baseline = np.empty((num_vid, TR_video_duration))\n",
    "            vid_avg_activity_rest_baseline[:] = np.nan\n",
    "            old_vid = np.empty(num_vid)\n",
    "            old_vid[:] = np.nan\n",
    "\n",
    "            #loop through all videos a subject saw\n",
    "            for vid_num, vid in enumerate(subj_log['Video_name']):\n",
    "            #     print('vid'+str(vid_num))\n",
    "\n",
    "                #get old/new info for each video\n",
    "                if subj_log['novel_vs_familiar(1-N,2-Old)'][vid_num] == 2:\n",
    "                    old_vid[vid_num] = 1\n",
    "                elif subj_log['novel_vs_familiar(1-N,2-Old)'][vid_num] == 1:\n",
    "                    old_vid[vid_num] = 0\n",
    "\n",
    "                #get video TR start and end\n",
    "                TR_begin = closest(TR_series, subj_log['video_onset'][vid_num]+TR_BOLD_offset)\n",
    "                # TR_mean_trial_duration = math.ceil((subj_log['video_offset'][vid_num] - subj_log['video_onset'][vid_num])/TR)\n",
    "                TR_end = TR_begin+TR_video_duration\n",
    "\n",
    "                #get video data from nearest TR start\n",
    "                if subj_log['run_number'][vid_num] == 1:\n",
    "                    vid_data = subj_run1_data[x_min:x_max,y_min:y_max,z_min:z_max,TR_begin:TR_end]\n",
    "                    #vid_data.shape\n",
    "                elif subj_log['run_number'][vid_num] == 2:\n",
    "                    vid_data = subj_run2_data[x_min:x_max,y_min:y_max,z_min:z_max,TR_begin:TR_end]\n",
    "                vid_data[vid_data==0.]=np.nan\n",
    "\n",
    "                #get average of activity in masked area at each slice\n",
    "                for i in range(vid_data.shape[3]):\n",
    "                #     #raw BOLD signal mean\n",
    "                #     vid_avg_activity[vid_num, i] = np.nanmean(vid_data)\n",
    "                    if subj_log['run_number'][vid_num] == 1:\n",
    "                        #BOLD signal mean with run1 rest period as baseline\n",
    "                        vid_avg_activity_rest_baseline[vid_num, i] = np.nanmean(vid_data[:,:,:,i])-rest_mean_run1\n",
    "                    elif subj_log['run_number'][vid_num] == 2:\n",
    "                        #BOLD signal mean with run2 rest period as baseline\n",
    "                        vid_avg_activity_rest_baseline[vid_num, i] = np.nanmean(vid_data[:,:,:,i])-rest_mean_run2\n",
    "\n",
    "            #get the old/new video timecourse seperately \n",
    "            vid_avg_activity_rest_baseline_old = vid_avg_activity_rest_baseline[old_vid==1, :]\n",
    "            vid_avg_activity_rest_baseline_new = vid_avg_activity_rest_baseline[old_vid==0, :]\n",
    "\n",
    "            #get autocorrelation for timecourse for average, new, and old images\n",
    "            correlation_coe = np.corrcoef(np.transpose(vid_avg_activity_rest_baseline))\n",
    "            correlation_coe[correlation_coe>=0.9999999999]=np.nan\n",
    "            correlation_coe_mean = np.nanmean(correlation_coe)\n",
    "            result_template_brain[x,y,z] = correlation_coe_mean\n",
    "            result_img = nib.Nifti1Image(result_template_brain, subj_data_img.affine, subj_data_img.header)\n",
    "            nib.save(result_img, save_dir+subj+'_corr_avg_'+fearType+'.nii.gz')\n",
    "\n",
    "            #new\n",
    "            correlation_coe_new = np.corrcoef(np.transpose(vid_avg_activity_rest_baseline_new))\n",
    "            correlation_coe_new[correlation_coe_new>=0.9999999999]=np.nan\n",
    "            correlation_coe_new_mean = np.nanmean(correlation_coe_new)\n",
    "            result_template_brain_new[x,y,z] = correlation_coe_new_mean\n",
    "            result_img_new = nib.Nifti1Image(result_template_brain_new, subj_data_img.affine, subj_data_img.header)\n",
    "            nib.save(result_img_new, save_dir+subj+'_corr_new_'+fearType+'.nii.gz')\n",
    "\n",
    "            #old\n",
    "            correlation_coe_old = np.corrcoef(np.transpose(vid_avg_activity_rest_baseline_old))\n",
    "            correlation_coe_old[correlation_coe_old>=0.9999999999]=np.nan\n",
    "            correlation_coe_old_mean = np.nanmean(correlation_coe_old)\n",
    "            result_template_brain_old[x,y,z] = correlation_coe_old_mean\n",
    "            result_img_old = nib.Nifti1Image(result_template_brain_old, subj_data_img.affine, subj_data_img.header)\n",
    "            nib.save(result_img_old, save_dir+subj+'_corr_old_'+fearType+'.nii.gz')\n",
    "\n",
    "        #     #get corr difference\n",
    "        #     correlation_coe_NEWvOLD = correlation_coe_new-correlation_coe_old\n",
    "        #     correlation_coe_mean = np.nanmean(correlation_coe_NEWvOLD)\n",
    "        #     #map the corr diff result to brain template\n",
    "        #     result_template_brain[x,y,z] = correlation_coe_mean\n",
    "        #     print('corr diff: '+str(correlation_coe_mean))\n",
    "        #     result_img = nib.Nifti1Image(result_template_brain, subj_data_img.affine, subj_data_img.header)\n",
    "        #     nib.save(result_img, '/home/chendanl/wrkdir/ISECmem_timecourse_searchlight_correlation_analysis/'+subj+'_corr_diff.nii.gz')\n",
    "\n",
    "        #     elapsed_time = time.time() - start_time\n",
    "        #     print(elapsed_time)\n",
    "\n",
    "    # # plotting.view_img('/home/chendanl/wrkdir/ISECmem_timecourse_searchlight_correlation_analysis/'+subj+'_corr_diff.nii.gz',cut_coordsNone=[10,38,35])\n",
    "    # plotting.view_img('/home/chendanl/wrkdir/ISECmem_timecourse_searchlight_correlation_analysis/'+subj+'_corr_diff.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #plot radius mask sample\n",
    "\n",
    "# mask_coordinate = mask_size[72000]\n",
    "# #     start_time = time.time()\n",
    "\n",
    "# #get the coordinates of the centered voxel\n",
    "# x = mask_location[0][mask_coordinate]\n",
    "# y = mask_location[1][mask_coordinate]\n",
    "# z = mask_location[2][mask_coordinate]\n",
    "\n",
    "# #get the range of coordinates based on the edge size vox\n",
    "# x_min = x-vox; y_min = y-vox; z_min = z-vox\n",
    "# x_max = x+vox+1; y_max = y+vox+1; z_max = z+vox+1;\n",
    "        \n",
    "# x=subj_run1_data[:,:,:,0]\n",
    "# x[:]=np.nan\n",
    "# x[x_min:x_max,y_min:y_max,z_min:z_max]=1\n",
    "# x[mask_img.get_fdata()==0]=np.nan\n",
    "\n",
    "# radius_mask_img = nib.Nifti1Image(x, subj_data_img.affine, subj_data_img.header)\n",
    "# nib.save(radius_mask_img, save_dir+'radius_mask_img.nii.gz')\n",
    "# plotting.view_img(save_dir+'radius_mask_img.nii.gz',cmap='rainbow',bg_img=mask_img)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
