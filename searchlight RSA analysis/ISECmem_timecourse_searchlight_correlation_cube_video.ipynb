{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import math\n",
    "from nilearn.image import resample_img\n",
    "from nilearn import plotting\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import statistics\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "os.chdir('/projects/hulacon/shared/neu_data/AVFP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_input=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heights_a_1.mp4\n"
     ]
    }
   ],
   "source": [
    "#get a full list of videoss\n",
    "logfile_folder = 'AffVidsMem_logfiles'\n",
    "log_header = ['Video_name', 'video_number', 'video_category(1-H 2-SO 3-SP)', 'novel_vs_familiar(1-N,2-Old)', 'run_number', 'video_onset', 'video_offset', 'video_duration_method1', 'video_duration_method2', 'Fear_rating_onset', 'fear_rating', 'fear_rating_RT', 'Arousal_rating_onset', 'arousal_rating', 'arousal_rating_RT', 'Valence_rating_onset', 'valence_rating', 'valence_rating_RT']\n",
    "log_files = glob.glob(logfile_folder+'/AffVidsMem*sub*.txt')\n",
    "log_files.sort()\n",
    "logs = pd.DataFrame()\n",
    "for n,s in enumerate(log_files):\n",
    "    subject_log = pd.read_table(s, sep=' ', header=None, names = log_header, index_col=False)\n",
    "    subject_log['subject']=s.split('.txt')[0].split('fmri_')[-1]\n",
    "    logs=logs.append(subject_log)\n",
    "logs=logs.reset_index(drop=True)\n",
    "vid_list = list(set(logs['Video_name']))\n",
    "vid_list.sort()\n",
    "video_name=vid_list[vid_input]\n",
    "print(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge: 5 voxels\n",
      "volume: 125 voxels\n"
     ]
    }
   ],
   "source": [
    "#get subject name from log file names\n",
    "data_folder = '36p'\n",
    "subj_dir = [i.split('.txt')[0].split('fmri_')[-1] for i in glob.glob(logfile_folder+'/AffVidsMem*sub*.txt')]\n",
    "subj_dir.sort()\n",
    "\n",
    "search_size = 5 #edge in voxel size\n",
    "vox = int((search_size-1)/2) #number of voxels from center voxel\n",
    "search_size = vox*2+1\n",
    "print('edge: '+str(search_size)+' voxels')\n",
    "print('volume: '+str(search_size**3)+' voxels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_header = ['Video_name', 'video_number', 'video_category(1-H 2-SO 3-SP)', 'novel_vs_familiar(1-N,2-Old)', 'run_number', 'video_onset', 'video_offset', 'video_duration_method1', 'video_duration_method2', 'Fear_rating_onset', 'fear_rating', 'fear_rating_RT', 'Arousal_rating_onset', 'arousal_rating', 'arousal_rating_RT', 'Valence_rating_onset', 'valence_rating', 'valence_rating_RT']\n",
    "# num_vid = pd.read_table(glob.glob(os.path.join(logfile_folder,'*'+subj_dir[0]+'.txt'))[0], sep=' ', header=None, names = log_header, index_col=False).shape[0]\n",
    "#sample subj data img for resampling\n",
    "subj_data_img = nib.load(glob.glob(os.path.join(data_folder,'sub-'+subj_dir[0][-3:]+'_run1_36p_mc_MNI_masked.nii.gz'))[0])\n",
    "subj_data = subj_data_img.get_fdata()\n",
    "\n",
    "TR=0.8\n",
    "num_TR = 600\n",
    "TR_series = [x*0.8 for x in range(0, num_TR)]\n",
    "TR_BOLD_offset = 7\n",
    "TR_video_duration = 26 #video_duration/0.8=25.6 round to 26\n",
    "TR_mean_rating= 5.3*3 #rating_duration/0.8=5.3 \n",
    "TR_mean_mean_ITI = 6 #ITI_duration/0.8=5.8 round to 6\n",
    "TR_trial_end = TR_video_duration+TR_mean_rating+TR_mean_mean_ITI\n",
    "\n",
    "#find the index of the closest number to K in a list\n",
    "def closest(lst, K): \n",
    "    val = lst[min(range(len(lst)), key = lambda i: abs(lst[i]-K))] \n",
    "    idx = lst.index(val)\n",
    "    return idx\n",
    "\n",
    "#use index of finding value x in 2D array (b) of value x as index of the first 2 dimensions for 3D array (a)\n",
    "def select3Dfrom2D(a,b,x):\n",
    "    b=old_vid.astype(int)\n",
    "    \n",
    "    new_array = []\n",
    "    for dim1 in list(set(np.where(b==x)[0])):\n",
    "        new_array.append(a[dim1,np.where(b==x)[1][np.where(b==x)[0]==dim1],:])\n",
    "    new_array = np.array(new_array)\n",
    "    \n",
    "    return new_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get grey matter mask\n",
    "save_dir = '/projects/hulacon/shared/neu_data/AVFP/ISECmem_timecourse_searchlight_correlation_analysis/a'+str(search_size)+'/video/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "# mask = '/home/chendanl/roi/HarvardOxford/HarvardOxford-cort-maxprob-thr25-1mm.nii.gz'\n",
    "# mask = '/home/chendanl/roi/HarvardOxford/HarvardOxford-sub-maxprob-thr25-1mm.nii.gz'\n",
    "mask = '/home/chendanl/roi/mni_icbm152_gm_tal_nlin_asym_09a_thresh30.nii.gz'\n",
    "mask_img = nib.load(mask)\n",
    "mask_img = resample_img(mask_img,\n",
    "                        target_affine=subj_data_img.affine,\n",
    "                        target_shape=subj_data_img.shape[0:3],\n",
    "                        interpolation='nearest')\n",
    "\n",
    "#get num of voxels\n",
    "# mask_location = np.where((mask_img.get_fdata()!=0) & (subj_data[:,:,:,0]!=0))\n",
    "mask_location = np.where(mask_img.get_fdata()!=0)\n",
    "mask_size = list(range(mask_location[0].shape[0]))\n",
    "\n",
    "# nib.save(mask_img, '/home/chendanl/wrkdir/roi.nii.gz')\n",
    "# display = plotting.plot_roi('/home/chendanl/wrkdir/roi.nii.gz', bg_img='/home/chendanl/roi/mni_icbm152_t1_tal_nlin_sym_09b_hires.nii')\n",
    "# plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of videos:\n",
      "51\n",
      "number of new videos:\n",
      "26\n",
      "number of old videos:\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#loop through each new and old list, \n",
    "vid_log = logs[logs['Video_name']==video_name]\n",
    "vid_log = vid_log.reset_index(drop=True)\n",
    "old_vid = np.empty(len(vid_log))\n",
    "old_vid[:] = np.nan\n",
    "# log_subset_video_old\n",
    "#load the sub data based on that, \n",
    "#calculate the baseline based on that too\n",
    "\n",
    "#set template for result map\n",
    "result_template_brain = mask_img.get_fdata().copy()\n",
    "result_template_brain[:]=np.nan\n",
    "result_template_brain_new = result_template_brain.copy()\n",
    "result_template_brain_old = result_template_brain.copy()\n",
    "\n",
    "#initialize list for averaged acitivty in mask: vid x TR\n",
    "vid_avg_activity_rest_baseline = np.empty((len(vid_log), TR_video_duration))\n",
    "vid_avg_activity_rest_baseline[:] = np.nan\n",
    "\n",
    "print('total number of videos:')\n",
    "print(vid_log.shape[0])\n",
    "print('number of new videos:')\n",
    "print(np.sum(vid_log['novel_vs_familiar(1-N,2-Old)'] == 2))\n",
    "print('number of old videos:')\n",
    "print(np.sum(vid_log['novel_vs_familiar(1-N,2-Old)'] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading existing array\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#see if the array already existed\n",
    "if os.path.exists(save_dir+video_name.split('.')[0]+'_array.npy'):\n",
    "    print('reading existing array')\n",
    "    existing_array = np.load(save_dir+video_name.split('.')[0]+'_array.npy')\n",
    "    vid_avg_activity_rest_baseline_voxel = existing_array\n",
    "    vid_range = list(set(np.where(existing_array==0)[0]))\n",
    "    vid_range.sort()\n",
    "    if vid_range[0] == 6 and vid_range[1] == 13 and vid_range[2] != 14:\n",
    "        vid_range=vid_range[2:]\n",
    "    if vid_avg_activity_rest_baseline_voxel[-1,-1,-1] != 0:\n",
    "        vid_range=[]\n",
    "else:\n",
    "    print('creating new array')\n",
    "    vid_avg_activity_rest_baseline_voxel = np.empty((vid_log.shape[0], TR_video_duration, len(mask_size)))\n",
    "    vid_range = range(vid_log.shape[0])\n",
    "print(vid_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate subject data so that don't need to read them over and over again later\n",
    "for n_vid in vid_range:\n",
    "    start = time.time()\n",
    "    print(n_vid)\n",
    "    subj=vid_log['subject'][n_vid]\n",
    "    run=vid_log['run_number'][n_vid]\n",
    "\n",
    "    #get run data\n",
    "    subj_run_f = glob.glob(os.path.join(data_folder,'sub-'+subj[-3:]+'_run'+str(run)+'_36p_mc_MNI_masked.nii.gz'))[0]\n",
    "    subj_run_img = nib.load(subj_run_f)\n",
    "    subj_run_data = subj_run_img.get_fdata()\n",
    "    subj_run_data[mask_img==0] = np.nan\n",
    "#     exec(\"subj_run_data_\" + str(n_vid) + \" = subj_run_img.get_fdata()\")\n",
    "#     exec(\"print(subj_run_data_\" + str(n_vid) + \".shape)\")\n",
    "\n",
    "    #read subject log file\n",
    "    subj_log_f = glob.glob(os.path.join(logfile_folder,'AffVidsMem*'+subj+'.txt'))[0]\n",
    "    subj_log = pd.read_table(subj_log_f, sep=' ', header=None, names = log_header, index_col=False) \n",
    "\n",
    "    for mask_coordinate in mask_size:\n",
    "        print('\\rworking on '+str(mask_coordinate) + ' out of '+str(max(mask_size)) + ' voxels, ' +str((mask_coordinate)/max(mask_size)*100) + '% done', end=\"\")\n",
    "\n",
    "        #get the coordinates of the centered voxel\n",
    "        x = mask_location[0][mask_coordinate]\n",
    "        y = mask_location[1][mask_coordinate]\n",
    "        z = mask_location[2][mask_coordinate]\n",
    "\n",
    "        #get the range of coordinates based on the edge size vox\n",
    "        x_min = x-vox; y_min = y-vox; z_min = z-vox\n",
    "        x_max = x+vox+1; y_max = y+vox+1; z_max = z+vox+1;\n",
    "\n",
    "        vid_num = subj_log.index[subj_log['Video_name']==video_name][0]\n",
    "\n",
    "        #calculate ITI period average\n",
    "        #get averanged run rest data\n",
    "        rest_mean_run_temp = []\n",
    "        trial_list = subj_log.index[subj_log['run_number'] == run].tolist()\n",
    "        for i in trial_list[0:len(trial_list)-1]:\n",
    "            #add TR offset to find time for ITI period\n",
    "            subj_run_rest_data = subj_run_data[x_min:x_max,y_min:y_max,z_min:z_max,closest(TR_series, (subj_log['Valence_rating_onset'][i]+TR_BOLD_offset+(TR_mean_rating/3)*TR)): closest(TR_series, subj_log['video_onset'][i+1]+TR_BOLD_offset)]\n",
    "            subj_run_rest_data[subj_run_rest_data==0.]=np.nan\n",
    "            rest_mean_run_temp.append(np.nanmean(subj_run_rest_data)) \n",
    "        rest_mean_run = np.nanmean(rest_mean_run_temp)\n",
    "\n",
    "        #get video TR start and end\n",
    "        TR_begin = closest(TR_series, subj_log['video_onset'][vid_num]+TR_BOLD_offset)\n",
    "        # TR_mean_trial_duration = math.ceil((subj_log['video_offset'][vid_num] - subj_log['video_onset'][vid_num])/TR)\n",
    "        TR_end = TR_begin+TR_video_duration\n",
    "\n",
    "        #get video data from nearest TR start\n",
    "        vid_data = subj_run_data[x_min:x_max,y_min:y_max,z_min:z_max,TR_begin:TR_end]\n",
    "        vid_data[vid_data==0.]=np.nan\n",
    "\n",
    "        #get average of activity in masked area at each slice\n",
    "        for i in range(vid_data.shape[3]):\n",
    "            #BOLD signal mean with run1 rest period as baseline\n",
    "            vid_avg_activity_rest_baseline_voxel[n_vid, i, mask_coordinate] = np.nanmean(vid_data[:,:,:,i])-rest_mean_run\n",
    "                \n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    np.save(save_dir+video_name.split('.')[0]+'_array.npy', vid_avg_activity_rest_baseline_voxel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 109 out of 166077 voxels, 0.06563220674747255% done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: Mean of empty slice\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:43: RuntimeWarning: Mean of empty slice\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:51: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 163219 out of 166077 voxels, 98.27911149647453% done"
     ]
    }
   ],
   "source": [
    "save_dir = '/projects/hulacon/shared/neu_data/AVFP/ISECmem_timecourse_searchlight_correlation_analysis/a'+str(search_size)+'/video/'\n",
    "vid_avg_activity_rest_baseline_voxel=np.load(save_dir+video_name.split('.')[0]+'_array.npy')\n",
    "\n",
    "#loop through all voxels\n",
    "save_dir = '/home/chendanl/wrkdir/ISECmem_timecourse_searchlight_correlation_analysis/a'+str(search_size)+'/'\n",
    "for mask_coordinate in mask_size:\n",
    "#     start = time.time()\n",
    "    print('\\rworking on '+str(mask_coordinate) + ' out of '+str(max(mask_size)) + ' voxels, ' +str((mask_coordinate)/max(mask_size)*100) + '% done', end=\"\")\n",
    "    #get the coordinates of the centered voxel\n",
    "    x = mask_location[0][mask_coordinate]\n",
    "    y = mask_location[1][mask_coordinate]\n",
    "    z = mask_location[2][mask_coordinate]\n",
    "    \n",
    "    #loop video\n",
    "    for n_vid in range(vid_log.shape[0]):\n",
    "#         print(n_vid)\n",
    "        subj=vid_log['subject'][n_vid]\n",
    "        run=vid_log['run_number'][n_vid]\n",
    "\n",
    "        #get old/new info for each video\n",
    "        if vid_log['novel_vs_familiar(1-N,2-Old)'][n_vid] == 2:\n",
    "            old_vid[n_vid] = 1\n",
    "        elif vid_log['novel_vs_familiar(1-N,2-Old)'][n_vid] == 1:\n",
    "            old_vid[n_vid] = 0\n",
    "            \n",
    "    vid_avg_activity_rest_baseline = vid_avg_activity_rest_baseline_voxel[:,:,mask_coordinate]\n",
    "            \n",
    "    #get the old/new video timecourse seperately \n",
    "    vid_avg_activity_rest_baseline_old = vid_avg_activity_rest_baseline[old_vid==1, :]\n",
    "    vid_avg_activity_rest_baseline_new = vid_avg_activity_rest_baseline[old_vid==0, :]\n",
    "\n",
    "    #get autocorrelation for timecourse for average, new, and old images\n",
    "    correlation_coe = np.corrcoef(np.transpose(vid_avg_activity_rest_baseline))\n",
    "    correlation_coe[correlation_coe>=0.9999999999]=np.nan\n",
    "    correlation_coe_mean = np.nanmean(correlation_coe)\n",
    "    result_template_brain[x,y,z] = correlation_coe_mean\n",
    "    result_img = nib.Nifti1Image(result_template_brain, subj_data_img.affine, subj_data_img.header)\n",
    "    nib.save(result_img, save_dir+video_name.split('.')[0]+'_corr_avg.nii.gz')\n",
    "\n",
    "    #new\n",
    "    correlation_coe_new = np.corrcoef(np.transpose(vid_avg_activity_rest_baseline_new))\n",
    "    correlation_coe_new[correlation_coe_new>=0.9999999999]=np.nan\n",
    "    correlation_coe_new_mean = np.nanmean(correlation_coe_new)\n",
    "    result_template_brain_new[x,y,z] = correlation_coe_new_mean\n",
    "    result_img_new = nib.Nifti1Image(result_template_brain_new, subj_data_img.affine, subj_data_img.header)\n",
    "    nib.save(result_img_new, save_dir+video_name.split('.')[0]+'_corr_new.nii.gz')\n",
    "\n",
    "    #old\n",
    "    correlation_coe_old = np.corrcoef(np.transpose(vid_avg_activity_rest_baseline_old))\n",
    "    correlation_coe_old[correlation_coe_old>=0.9999999999]=np.nan\n",
    "    correlation_coe_old_mean = np.nanmean(correlation_coe_old)\n",
    "    result_template_brain_old[x,y,z] = correlation_coe_old_mean\n",
    "    result_img_old = nib.Nifti1Image(result_template_brain_old, subj_data_img.affine, subj_data_img.header)\n",
    "    nib.save(result_img_old, save_dir+video_name.split('.')[0]+'_corr_old.nii.gz')\n",
    "\n",
    "#     end = time.time()\n",
    "#     print(end - start)\n",
    "# # plotting.view_img('/home/chendanl/wrkdir/ISECmem_timecourse_searchlight_correlation_analysis/'+subj+'_corr_diff.nii.gz',cut_coordsNone=[10,38,35])\n",
    "# plotting.view_img(result_img, save_dir+video_name.split('.')[0]+'_corr_avg.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting.view_img('/home/chendanl/wrkdir/ISECmem_timecourse_searchlight_correlation_analysis/a5/Heights_a_1_corr_avg.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
